<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>HumanNeRF-SE</title>

    <meta name="description" content="HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with Diverse Poses">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!-- FACEBOOK -->
    <!-- <meta property="og:image" content="https://bakedsdf.github.io/img/breakdown_new.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://bakedsdf.github.io"/>
    <meta property="og:title" content="BakedSDF" />
    <meta property="og:description" content="Project page for BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis." /> -->

        <!--TWITTER-->
    <!-- <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="BakedSDF" />
    <meta name="twitter:description" content="Project page for BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis." />
    <meta name="twitter:image" content="https://bakedsdf.github.io/img/breakdown_new.png"/> -->


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üçû</text></svg>">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>
	
<!--
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
-->
	
	<link rel="stylesheet" href="css/dics.min.css">
    <script src="scripts/dics.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', domReady);
        function domReady() {
            for (const e of document.querySelectorAll(".b-dics")) {
                new Dics({
                    container: e,
                    textPosition: "top"
                });
            }
        }
    </script>
	
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with Diverse Poses <br>
                <small>
                    Caoyuan Ma, Yu-Lun Liu, Zhixiang Wang, Wu Liu, Xinchen Liu, Zheng Wang
                    <br>
                    Wuhan University, JD Explore Academy,National Yang Ming Chiao Tung University, The University of Tokyo, National Institute of Informatics
                </small>
            </h2>
        </div>


        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <!-- <a href="img/arxiv-version.pdf"> -->
                            <a href=‚Äúhttps://arxiv.org/abs/2312.02232‚Äù>
                            <image src="img/bake_paper_image.png" height="120px"></image>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="img/youtube_icon.png" target="_blank">
                            <image src="img/youtube_icon.png" height="120px"></image>
                                <h4><strong>Video(Coming soon)</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/Miles629/HumanNeRF-SE">
                            <image src="img/github.png" height="120px"></image>
                                <h4><strong>Codes</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Teaser
                </h3>
                <div style="position:relative;padding-top:30%;">
                <image src="img/teaser24.png" allowfullscreen style="position:absolute;top:0;left:0;width:100%;"></image>
                </div>
                <strong>Overview.</strong> We synthesize images of performers in diverse poses in a simple yet effective way. (a) Novel Pose: In order to test the ability of synthesizing images of diverse poses, we input a simple action video and animate it with novel poses. (b) Few Shot: Furthermore, to test the ability to avoid overfitting, we use only few input to generalize novel pose images. (c) Compared to similar methods, HumanNeRF-SE uses less than 1% of learnable parameters, 1/20 training time, and achieves better results in few-shot experiments. ‚Ä†LPIPS = 1,000√óLPIPS. 
                <h3>
                    Abstract
                </h3>
                <!-- <image src="img/rays.jpg" class="img-responsive" alt="overview"><br> -->
                <p class="text-justify">
                    We present HumanNeRF-SE, which can synthesize diverse novel pose images with simple input. Previous HumanNeRF studies require large neural networks to fit the human appearance and prior knowledge. Subsequent methods build upon this approach with some improvements. Instead, we reconstruct this approach, combining explicit and implicit human representations with both general and specific mapping processes.

                    Our key insight is that explicit shape can filter the information used to fit implicit representation, and frozen general mapping combined with point-specific mapping can effectively avoid overfitting and improve pose generalization performance.Our explicit and implicit human represent combination architecture is extremely effective. This is reflected in our model's ability to synthesize images under arbitrary poses with few-shot input and increase the speed of synthesizing images by 15 times through a reduction in computational complexity without using any existing acceleration modules. Compared to the state-of-the-art HumanNeRF studies, HumanNeRF-SE achieves better performance with fewer learnable parameters and less training time (see Figure 1).
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video(Coming soon)
                </h3>
                <div class="text-justify">
                    <!-- <div style="position:relative;padding-top:50%;">
                        <iframe src="img/suppl-video.mp4" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div> -->
                </div>
            </div>
        </div>
        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:70%;">
                        <iframe src="img/suppl-video.mp4" allowfullscreen style="position:absolute;top:0;left:0;width:120%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->


        <div class="row">
            <div class="col-md-8 col-md-offset-2" id="demos">
                <h3>
                    Structure
                </h3>
                <div class="text-justify">
                    <div style="position:relative;padding-top:50%;">
                        <image src="img/method_page.png" allowfullscreen style="position:absolute;top:0;left:0;width:100%;"></image>
                        <p><strong>Framework of HumanNeRF-SE.</strong>(a) We first voxelize the observation space as a voxel volume V . For a voxel containing vertices, the value will be the number of vertices (as one occupancy channel) and the corresponding SMPL weight. (b) We performed channel-by-channel convolution on the volume. All sampling points are queried in the convolutional volume to get their spatial-aware features. Those points with zero occupancy will be filtered out. (c) We query the nearest weight of the remained points in the volume, which is used for rigid deformation. Spatial-aware features are utilized in the neural network to correct the rigid results and obtain the final point coordinates in the canonical space. (d) The sampling points in the canonical space obtain their colors and densities through the NeRF network. The densities of filtered points are forced to be zero.</p>
                    </div>
                </div>
                <!-- <h4>
                    Real Captured Scenes
                </h4> -->
            </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2 ">
                <h3>
                    Demo
                </h3>
                <h4>We use ROMP to estimate SMPL as prior from the network video. Due to the fast motion  present in dance videos, the estimated SMPL is jittery. Our method is still significantly superior compared to the baseline.</h4>
                <div class="text-justify">
                    <div style="position:relative;padding-top:50%;">
                        <iframe src="img/demo3.mp4" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        
                        <li>
                            <image src="img/iftime/377_movement.gif" width="260px"></image>
                                <h4><strong>Ours377</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/hn377_movement.gif" width="260px"></image>
                                <h4><strong>HumanNeRF377</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/mono377_movement.gif" width="260px"></image>
                                <h4><strong>MonoHuman377</strong></h4>
                            </a>
                        </li>
                        <br>
                        <li>
                            <image src="img/iftime/386_movement.gif" width="260px"></image>
                                <h4><strong>Ours386</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/hn386_movement.gif" width="260px"></image>
                                <h4><strong>HumanNeRF386</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/mono386_movement.gif" width="260px"></image>
                                <h4><strong>MonoHuman386</strong></h4>
                            </a>
                        </li>
                        <br>
                        <li>
                            <image src="img/iftime/392_movement.gif" width="260px"></image>
                                <h4><strong>Ours392</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/hn392_movement.gif" width="260px"></image>
                                <h4><strong>HumanNeRF392</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/mono392_movement.gif" width="260px"></image>
                                <h4><strong>MonoHuman392</strong></h4>
                            </a>
                        </li>
                        <br>
                        <li>
                            <image src="img/iftime/393_movement.gif" width="260px"></image>
                                <h4><strong>Ours393</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/hn393_movement.gif" width="260px"></image>
                                <h4><strong>HumanNeRF393</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/mono393_movement.gif" width="260px"></image>
                                <h4><strong>MonoHuman393</strong></h4>
                            </a>
                        </li>
                        <br>
                        <li>
                            <image src="img/iftime/394_movement.gif" width="260px"></image>
                                <h4><strong>Ours394</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/hn394_movement.gif" width="260px"></image>
                                <h4><strong>HumanNeRF394</strong></h4>
                            </a>
                        </li>
                        <li>
                            <image src="img/iftime/mono394_movement.gif" width="260px"></image>
                                <h4><strong>MonoHuman394</strong></h4>
                            </a>
                        </li>
						
                        
							
						<!-- <li>
							<style>
							.disabled-link {
							  pointer-events: none;
 							  color: grey;
							}
							</style>
                            <a href="https://bakedsdf.github.io/viewer/index.html?scene=https://dl.dropboxusercontent.com/s/zw6trrwjnh56pyp/kitchencounter.glb" class="disabled-link">
                            <image src="img/flowertreehill.png" width="260px"></image>
                                <h4 ><strong>Treehill & Flower </strong></h4>
							</a>
						</li> -->
                    </ul>
                </div>
        </div>
	


        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BakedSDF
                </h3>
                <br>
                <image src="img/breakdown_new.png" style="width:100%;" class="img-responsive center-block" alt="overview"></image>
                <br>
                <p class="text-justify">
                    Our method bakes a hybrid VolSDF/mip-NeRF 360 scene representation into a triangle mesh, then optimizes a lightweight view-dependent appearance model to reproduce the training images. The final color of the rendered mesh is a sum of spherical Gaussian lobes (queried with the outgoing view direction) and a diffuse color. These parameters are stored per-vertex on the underlying mesh.
                </p>
            </div>
        </div>
		
		<div class="row comp-margin">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Mesh Extraction and Rendering
                </h3>
                <div class="b-dics" style="width: 100%">
                    <img src="img/gardenvase_mesh_ours.jpg" alt="Mesh" />
                    <img src="img/gardenvase_rendering.jpg" alt="Rendering" />
                </div>
            </div>
        </div>
		<br>
		
		<div class="row comp-margin">
            <div class="col-md-8 col-md-offset-2">
                <div class="b-dics" style="width: 100%">
                    <img src="img/mesh.014.jpg" alt="Mesh" />
                    <img src="img/final.014.jpg" alt="Rendering" />
                </div>
            </div>
        </div> -->




<!--
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Related links
                </h3>
                <p class="text-justify">
                  Something something? or delete. could be like mipnerf360/volsdf, something that uses spherical gaussians? idk
                </p>
                </p>
            </div>
        </div>
-->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                The website template was borrowed from <a href="http://mgharbi.com/">Micha√´l Gharbi</a>.
                </p>
            </div>
        </div>

    </div>
</body>
</html>
